#!/usr/bin/env python3
"""
Run gap analysis on Target handbags data: style clustering (K-Means/HDBSCAN),
PCA/UMAP, price segmentation, rating quadrants, brand dominance, color diversity,
title-keyword co-occurrence, and six practical gap analyses. Outputs enriched
CSV/JSON and a markdown report.
"""
from __future__ import annotations

import argparse
import json
import logging
import re
import sys
from datetime import datetime
from pathlib import Path

import numpy as np
import pandas as pd

# Project root
SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPT_DIR.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

try:
    from dotenv import load_dotenv
    load_dotenv(PROJECT_ROOT / ".env")
except ImportError:
    pass

from analysis.utils import build_style_text, load_products

logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)

# Constants
MAX_DOCUMENT_CHARS = 500
PRICE_BANDS = [(0, 20), (20, 40), (40, 70), (70, 120), (120, float("inf"))]
PRICE_BAND_LABELS = ["0-20", "20-40", "40-70", "70-120", "120+"]
RATING_HIGH_THRESHOLD = 4.0
REVIEW_COUNT_HIGH_DEFAULT = 20  # or median-based
TITLE_KEYWORDS = [
    "tote", "clutch", "backpack", "crossbody", "convertible", "quilted",
    "faux leather", "laptop", "organizer", "mini", "drawstring",
]
COLOR_FAMILY_MAP = {
    "black": "black",
    "white": "neutral", "cream": "neutral", "gray": "neutral", "grey": "neutral",
    "beige": "neutral", "tan": "neutral", "ivory": "neutral", "nude": "neutral",
    "pink": "pastel", "blue": "pastel", "lavender": "pastel", "mint": "pastel",
    "yellow": "pastel", "peach": "pastel", "rose": "pastel", "misty rose": "pastel",
    "red": "bold", "navy": "bold", "olive": "bold", "burgundy": "bold",
    "brown": "neutral", "khaki": "neutral", "gold": "bold", "silver": "neutral",
}


def save_umap_scatter(
    df: pd.DataFrame,
    out_path: Path,
    color_by: str = "cluster_kmeans",
    title: str | None = None,
) -> None:
    """Save a simple UMAP scatter plot (PNG) for quick visual inspection."""
    try:
        import matplotlib.pyplot as plt
    except ImportError as e:  # pragma: no cover
        raise ImportError(
            "UMAP plotting requires matplotlib. Install with: pip install matplotlib"
        ) from e

    needed = {"umap_x", "umap_y", color_by}
    missing = [c for c in needed if c not in df.columns]
    if missing:
        raise ValueError(f"Cannot plot UMAP; missing columns: {missing}")

    plot_df = df[["umap_x", "umap_y", color_by]].dropna(subset=["umap_x", "umap_y"]).copy()
    if plot_df.empty:
        raise ValueError("Cannot plot UMAP; no non-null UMAP coordinates.")

    fig, ax = plt.subplots(figsize=(10, 7), dpi=150)

    series = plot_df[color_by]
    if pd.api.types.is_numeric_dtype(series):
        sc = ax.scatter(plot_df["umap_x"], plot_df["umap_y"], c=series, s=10, alpha=0.75, cmap="viridis")
        fig.colorbar(sc, ax=ax, label=color_by)
    else:
        cats = series.astype("category")
        codes = cats.cat.codes
        sc = ax.scatter(plot_df["umap_x"], plot_df["umap_y"], c=codes, s=10, alpha=0.75, cmap="tab20")
        # Legend only if the number of categories is reasonable
        cat_names = list(cats.cat.categories)
        if len(cat_names) <= 20:
            handles = []
            for idx, name in enumerate(cat_names):
                handles.append(
                    plt.Line2D([0], [0], marker="o", linestyle="", markersize=6, label=str(name),
                               markerfacecolor=sc.cmap(idx / max(1, len(cat_names) - 1)), markeredgecolor="none")
                )
            ax.legend(handles=handles, title=color_by, loc="best", fontsize=8, title_fontsize=9)

    ax.set_xlabel("UMAP 1")
    ax.set_ylabel("UMAP 2")
    ax.set_title(title or f"UMAP scatter (colored by {color_by})")
    ax.grid(False)
    fig.tight_layout()

    out_path = Path(out_path)
    out_path.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(out_path)
    plt.close(fig)


def _coerce_float(v, default: float = 0.0) -> float:
    if v is None or v == "":
        return default
    if isinstance(v, (int, float)):
        return float(v)
    try:
        return float(str(v).strip())
    except (ValueError, TypeError):
        return default


def _coerce_bool(v) -> bool:
    if v is None:
        return False
    if isinstance(v, bool):
        return v
    s = str(v).strip().lower()
    return s in ("true", "1", "yes")


def compute_style_embeddings_clip(texts: list[str], device: str = "cpu") -> np.ndarray:
    """Compute CLIP text embeddings for a list of strings (text-only, no images)."""
    import torch
    import clip

    logger.info("Loading CLIP model ViT-B/32 on %s...", device)
    model, _ = clip.load("ViT-B/32", device=device)
    model.eval()

    truncated = []
    for t in texts:
        t = (t or " ").strip()
        if len(t) > MAX_DOCUMENT_CHARS:
            t = t[:MAX_DOCUMENT_CHARS].rsplit(" ", 1)[0] or t[:MAX_DOCUMENT_CHARS]
        truncated.append(t or " ")

    embeddings_list = []
    batch_size = 32
    for i in range(0, len(truncated), batch_size):
        batch = truncated[i : i + batch_size]
        with torch.no_grad():
            tokens = clip.tokenize(batch, truncate=True).to(device)
            features = model.encode_text(tokens)
            features = features / features.norm(dim=-1, keepdim=True)
            embeddings_list.append(features.cpu().float().numpy())
        if (i + batch_size) % 64 == 0 or i + batch_size >= len(truncated):
            logger.info("Computed embeddings %d/%d.", min(i + batch_size, len(truncated)), len(truncated))

    return np.vstack(embeddings_list)


def compute_style_embeddings_tfidf(texts: list[str]) -> np.ndarray:
    """Fallback: TF-IDF embeddings (no torch/CLIP). Use for --quick-test."""
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.preprocessing import Normalizer

    vec = TfidfVectorizer(max_features=256, strip_accents="unicode", lowercase=True)
    X = vec.fit_transform([t or " " for t in texts])
    normalizer = Normalizer(norm="l2")
    return normalizer.fit_transform(X).toarray().astype(np.float32)


def assign_price_band(product: dict) -> str:
    """Assign price band; use price_regular/sale_price if price_current is 0."""
    p = _coerce_float(product.get("price_current"))
    if p <= 0:
        p = _coerce_float(product.get("price_regular")) or _coerce_float(product.get("sale_price"))
    if p <= 0:
        return "unknown"
    for (lo, hi), label in zip(PRICE_BANDS, PRICE_BAND_LABELS):
        if lo <= p < hi:
            return label
    return PRICE_BAND_LABELS[-1]


def assign_rating_quadrant(rating: float, rating_count: float, review_high_threshold: int) -> str:
    """Proven winner / Hidden opportunity / Market mismatch / Weak."""
    high_rating = rating >= RATING_HIGH_THRESHOLD
    high_reviews = rating_count >= review_high_threshold
    if high_rating and high_reviews:
        return "Proven winner"
    if high_rating and not high_reviews:
        return "Hidden opportunity"
    if not high_rating and high_reviews:
        return "Market mismatch"
    return "Weak"


def parse_colors(colors_str: str) -> tuple[int, str]:
    """Return (color_count, primary_color_family). 'plus N more' not counted as literal color."""
    if not colors_str or not str(colors_str).strip():
        return 0, "unknown"
    s = str(colors_str).strip()
    # Split by | or " and "
    parts = re.split(r"\s*\|\s*|\s+and\s+", s, flags=re.I)
    count = 0
    families = []
    for p in parts:
        p = p.strip()
        if not p:
            continue
        if re.match(r"plus\s+\d+\s+more", p, re.I):
            continue
        count += 1
        low = p.lower()
        family = "unknown"
        for key, fam in COLOR_FAMILY_MAP.items():
            if key in low or low in key:
                family = fam
                break
        families.append(family)
    primary = families[0] if families else "unknown"
    return count, primary


def extract_title_keywords(title: str) -> dict[str, bool]:
    """Binary flags for TITLE_KEYWORDS (case-insensitive word boundary)."""
    t = (title or "").lower()
    return {kw: bool(re.search(r"\b" + re.escape(kw) + r"\b", t)) for kw in TITLE_KEYWORDS}


def run_gap_analysis(
    input_path: Path,
    output_dir: Path,
    n_clusters: int = 5,
    run_hdbscan: bool = True,
    run_umap: bool = True,
    review_high_threshold: int | None = None,
    quick_test: bool = False,
    plot_umap: bool = False,
    umap_color_by: str = "cluster_kmeans",
) -> None:
    """Load data, embed, cluster, analyze, write enriched data and report."""
    products = load_products(input_path)
    logger.info("Loaded %d products from %s", len(products), input_path)
    if not products:
        logger.error("No products to analyze.")
        return

    # Build style text and embeddings
    style_texts = [build_style_text(p) for p in products]
    if quick_test:
        logger.info("Quick-test mode: using TF-IDF embeddings (no CLIP).")
        embeddings = compute_style_embeddings_tfidf(style_texts)
    else:
        try:
            import torch
            device = "cuda" if torch.cuda.is_available() else "cpu"
        except ImportError:
            raise ImportError(
                "Gap analysis requires PyTorch and CLIP for style embeddings. "
                "Install with: pip install torch; pip install git+https://github.com/openai/CLIP.git. "
                "Or run with --quick-test to use TF-IDF (no torch)."
            ) from None
        embeddings = compute_style_embeddings_clip(style_texts, device=device)
    logger.info("Computed %d style embeddings.", len(embeddings))

    # DataFrame from products (coerce types for CSV-loaded data)
    df = pd.DataFrame(products)
    df["style_text"] = style_texts

    # Price band
    df["price_band"] = [assign_price_band(p) for p in products]
    price_current_num = [_coerce_float(p.get("price_current")) or _coerce_float(p.get("price_regular")) or _coerce_float(p.get("sale_price")) for p in products]
    df["price_numeric"] = price_current_num

    # Rating / review
    ratings = [_coerce_float(p.get("rating")) for p in products]
    rating_counts = [_coerce_float(p.get("rating_count")) for p in products]
    df["rating"] = ratings
    df["rating_count"] = rating_counts
    if review_high_threshold is None:
        review_high_threshold = int(np.median(rating_counts)) if rating_counts else REVIEW_COUNT_HIGH_DEFAULT
    df["rating_quadrant"] = [
        assign_rating_quadrant(r, rc, review_high_threshold) for r, rc in zip(ratings, rating_counts)
    ]

    # Color count and family
    color_parsed = [parse_colors(p.get("colors")) for p in products]
    df["color_count"] = [c for c, _ in color_parsed]
    df["color_family"] = [f for _, f in color_parsed]

    # Title keyword flags
    for kw in TITLE_KEYWORDS:
        col = "kw_" + kw.replace(" ", "_")
        df[col] = [extract_title_keywords(p.get("title") or "").get(kw, False) for p in products]

    # Booleans
    df["is_sale"] = [_coerce_bool(p.get("is_sale")) for p in products]
    df["is_clearance"] = [_coerce_bool(p.get("is_clearance")) for p in products]
    df["is_new"] = [_coerce_bool(p.get("is_new")) for p in products]
    df["best_seller"] = [_coerce_bool(p.get("best_seller")) for p in products]
    df["in_stock"] = [_coerce_bool(p.get("in_stock")) for p in products]

    # K-Means
    from sklearn.cluster import KMeans
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    df["cluster_kmeans"] = kmeans.fit_predict(embeddings)

    # PCA
    from sklearn.decomposition import PCA
    pca = PCA(n_components=2, random_state=42)
    pca_2d = pca.fit_transform(embeddings)
    df["pca_x"] = pca_2d[:, 0]
    df["pca_y"] = pca_2d[:, 1]

    # HDBSCAN
    if run_hdbscan:
        try:
            import hdbscan
            clusterer = hdbscan.HDBSCAN(min_cluster_size=2, min_samples=1, metric="euclidean")
            df["cluster_hdbscan"] = clusterer.fit_predict(embeddings)
        except Exception as e:
            logger.warning("HDBSCAN failed: %s. Skipping.", e)
            df["cluster_hdbscan"] = -1
    else:
        df["cluster_hdbscan"] = -1

    # UMAP
    if run_umap:
        try:
            import umap
            reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=min(15, len(embeddings) - 1))
            umap_2d = reducer.fit_transform(embeddings)
            df["umap_x"] = umap_2d[:, 0]
            df["umap_y"] = umap_2d[:, 1]
        except Exception as e:
            logger.warning("UMAP failed: %s. Skipping.", e)
            df["umap_x"] = np.nan
            df["umap_y"] = np.nan
    else:
        df["umap_x"] = np.nan
        df["umap_y"] = np.nan

    # Cluster column for report (use K-Means)
    cluster_col = "cluster_kmeans"

    # Write outputs
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    base = f"gap_analysis_handbags_{ts}"

    enriched_csv = output_dir / f"{base}.csv"
    enriched_json = output_dir / f"{base}.json"
    report_md = output_dir / f"{base}_report.md"
    umap_png = output_dir / f"{base}_umap.png"

    # Optional: UMAP plot (generate before report so report can embed it)
    umap_plot_written = False
    if plot_umap:
        if not run_umap:
            raise ValueError("--plot-umap requested but UMAP was disabled (use without --no-umap).")
        try:
            save_umap_scatter(
                df,
                out_path=umap_png,
                color_by=umap_color_by,
                title=f"UMAP: {len(df)} products (colored by {umap_color_by})",
            )
            umap_plot_written = True
            logger.info("Wrote %s", umap_png)
        except Exception as e:
            logger.warning("UMAP plot failed: %s", e)

    # --- Build report sections ---
    report_lines = [
        "# Gap Analysis Report",
        "",
        f"Generated: {datetime.now().isoformat()}",
        f"Input: {input_path}",
        f"Products: {len(df)}",
        f"Outputs: {enriched_csv.name}, {enriched_json.name}",
        "",
        "---",
        "",
        "## 0. Visual evidence",
        "",
        (
            f"UMAP scatter (colored by `{umap_color_by}`): ![]({umap_png.name})"
            if umap_plot_written
            else "UMAP scatter: (not generated)"
        ),
        "",
        "---",
        "",
        "## 1. Summary",
        "",
        f"- **Products:** {len(df)}",
        f"- **Style clusters (K-Means k={n_clusters}):** {df[cluster_col].nunique()}",
        f"- **Price bands:** {df['price_band'].nunique()} ({', '.join(PRICE_BAND_LABELS)} + unknown)",
        "",
        "---",
        "",
        "## 2. Style clusters (SKU count, avg price, avg rating, dominant brand)",
        "",
    ]

    for c in sorted(df[cluster_col].unique()):
        sub = df[df[cluster_col] == c]
        n = len(sub)
        avg_price = sub["price_numeric"].replace(0, np.nan).mean()
        avg_price_str = f"{avg_price:.1f}" if not np.isnan(avg_price) else "—"
        avg_rating = sub["rating"].replace(0, np.nan).mean()
        avg_rating_str = f"{avg_rating:.2f}" if not np.isnan(avg_rating) else "—"
        top_brand = sub["brand"].mode().iloc[0] if "brand" in sub.columns and len(sub["brand"].mode()) else "—"
        report_lines.append(f"- **Cluster {c}:** SKUs={n}, avg_price={avg_price_str}, avg_rating={avg_rating_str}, top_brand={top_brand}")
    report_lines.extend(["", "---", "", "## 3. SKU density (cluster × price band)", ""])

    # Pivot (use string table; to_markdown requires tabulate)
    pivot = pd.crosstab(df[cluster_col], df["price_band"], margins=True)
    report_lines.append("```")
    report_lines.append(pivot.to_string())
    report_lines.append("```")
    report_lines.extend(["", "*(Empty or near-zero cells = price–style gap)*", "", "---", "", "## 4. Rating × review quadrant", ""])

    quad_counts = df["rating_quadrant"].value_counts()
    for q, cnt in quad_counts.items():
        report_lines.append(f"- **{q}:** {cnt}")
    report_lines.extend(["", "Hidden winners (high rating, low reviews) by cluster:", ""])
    hidden = df[df["rating_quadrant"] == "Hidden opportunity"].groupby(cluster_col).size()
    for c, cnt in hidden.items():
        report_lines.append(f"- Cluster {c}: {cnt}")
    report_lines.extend(["", "---", "", "## 5. Brand dominance (per cluster)", ""])

    for c in sorted(df[cluster_col].unique()):
        sub = df[df[cluster_col] == c]
        brand_counts = sub["brand"].value_counts()
        total = len(sub)
        top = brand_counts.iloc[0] if len(brand_counts) else 0
        pct = 100 * top / total if total else 0
        report_lines.append(f"- **Cluster {c}:** top brand share = {pct:.0f}% — {'dominance' if pct >= 70 else 'mixed/white-space'}")
    report_lines.extend(["", "---", "", "## 6. Color diversity (by cluster)", ""])

    for c in sorted(df[cluster_col].unique()):
        sub = df[df[cluster_col] == c]
        report_lines.append(f"- **Cluster {c}:** avg color_count={sub['color_count'].mean():.1f}, main families: {sub['color_family'].value_counts().head(3).to_dict()}")
    report_lines.extend(["", "---", "", "## 7. Title keyword co-occurrence (gaps)", ""])

    # Co-occurrence
    kw_cols = ["kw_" + k.replace(" ", "_") for k in TITLE_KEYWORDS]
    cooc = {}
    for i, ki in enumerate(TITLE_KEYWORDS):
        for j, kj in enumerate(TITLE_KEYWORDS):
            if i < j:
                pair = (ki, kj)
                count = ((df["kw_" + ki.replace(" ", "_")] == True) & (df["kw_" + kj.replace(" ", "_")] == True)).sum()
                cooc[pair] = count
    sorted_pairs = sorted(cooc.items(), key=lambda x: -x[1])
    report_lines.append("Top pairs (count):")
    for (k1, k2), cnt in sorted_pairs[:5]:
        report_lines.append(f"- {k1} + {k2}: {cnt}")
    report_lines.append("")
    report_lines.append("Gaps (zero or sparse):")
    for (k1, k2), cnt in sorted_pairs:
        if cnt <= 1:
            report_lines.append(f"- {k1} + {k2}: {cnt}")
    report_lines.extend(["", "---", "", "## 8. Six gap analyses", ""])

    # Rating-weighted cluster strength
    df["score_weight"] = df["rating"] * np.log(df["rating_count"] + 1)
    cluster_score = df.groupby(cluster_col).agg(cluster_score=("score_weight", "mean"))
    cluster_score["sku_count"] = df.groupby(cluster_col).size()
    report_lines.append("### 8.1 Rating-weighted cluster strength")
    report_lines.append("")
    report_lines.append("```")
    report_lines.append(cluster_score.sort_values("cluster_score", ascending=False).to_string())
    report_lines.append("```")
    report_lines.append("")
    report_lines.append("- High score + low SKU count → expand. Low score + high SKU count → over-indexed.")
    report_lines.extend(["", "### 8.2 New vs established", ""])
    new_by_cluster = df.groupby(cluster_col)["is_new"].sum()
    report_lines.append("```")
    report_lines.append(new_by_cluster.to_string())
    report_lines.append("```")
    report_lines.append("")
    report_lines.append("- If new SKUs concentrated in one cluster → not innovating in other styles.")
    report_lines.extend(["", "### 8.3 Bestseller gap", ""])
    best = df[df["best_seller"] == True]
    if len(best):
        report_lines.append(f"Bestsellers in clusters: {best[cluster_col].value_counts().to_dict()}")
        report_lines.append("")
        report_lines.append("- If bestseller cluster has few total SKUs → expand in that direction.")
    else:
        report_lines.append("No best_seller=True in dataset.")
    report_lines.extend(["", "### 8.4 Clearance pattern", ""])
    clearance_pct = df.groupby(cluster_col)["is_clearance"].mean() * 100
    report_lines.append("```")
    report_lines.append(clearance_pct.to_string())
    report_lines.append("```")
    report_lines.append("")
    report_lines.append("- High clearance % in a cluster → possible weak demand.")
    report_lines.extend(["", "### 8.5 In-stock pressure", ""])
    out_of_stock_pct = (1 - df.groupby(cluster_col)["in_stock"].mean()) * 100
    report_lines.append("```")
    report_lines.append(out_of_stock_pct.to_string())
    report_lines.append("```")
    report_lines.append("")
    report_lines.append("- High out-of-stock % → demand signal.")
    report_lines.extend(["", "---", "", "*Internal trend map; competitor comparison when data available.*", ""])

    report_text = "\n".join(report_lines)

    # CSV: convert bool to int for cleaner export if needed; keep as bool
    df.to_csv(enriched_csv, index=False)
    logger.info("Wrote %s", enriched_csv)

    # JSON: list of dicts (drop numpy types)
    records = df.replace({np.nan: None}).to_dict("records")
    for r in records:
        for k, v in list(r.items()):
            if isinstance(v, (np.integer, np.floating)):
                r[k] = float(v) if isinstance(v, np.floating) else int(v)
            elif isinstance(v, np.bool_):
                r[k] = bool(v)
    with open(enriched_json, "w", encoding="utf-8") as f:
        json.dump(records, f, indent=2)
    logger.info("Wrote %s", enriched_json)

    with open(report_md, "w", encoding="utf-8") as f:
        f.write(report_text)
    logger.info("Wrote %s", report_md)


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Run gap analysis: clustering, price/rating/brand/color/co-occurrence, six gap analyses."
    )
    parser.add_argument(
        "input",
        type=Path,
        nargs="?",
        default=PROJECT_ROOT / "output" / "target_handbags_20260220_213726.csv",
        help="Path to JSON, JSONL, or CSV",
    )
    parser.add_argument(
        "-o", "--output-dir",
        type=Path,
        default=PROJECT_ROOT / "output",
        help="Output directory for enriched data and report",
    )
    parser.add_argument(
        "-k", "--clusters",
        type=int,
        default=5,
        help="K-Means n_clusters (default 5)",
    )
    parser.add_argument(
        "--no-hdbscan",
        action="store_true",
        help="Skip HDBSCAN",
    )
    parser.add_argument(
        "--no-umap",
        action="store_true",
        help="Skip UMAP",
    )
    parser.add_argument(
        "--review-high",
        type=int,
        default=None,
        help="Review count threshold for 'high' in quadrant (default: median)",
    )
    parser.add_argument(
        "--quick-test",
        action="store_true",
        help="Use TF-IDF embeddings instead of CLIP (no torch required)",
    )
    parser.add_argument(
        "--plot-umap",
        action="store_true",
        help="Save a UMAP scatter plot PNG in the output directory",
    )
    parser.add_argument(
        "--umap-color-by",
        type=str,
        default="cluster_kmeans",
        help="Column to color UMAP points by (default: cluster_kmeans). Examples: price_band, rating_quadrant, brand",
    )
    args = parser.parse_args()
    run_gap_analysis(
        input_path=args.input,
        output_dir=args.output_dir,
        n_clusters=args.clusters,
        run_hdbscan=not args.no_hdbscan,
        run_umap=not args.no_umap,
        review_high_threshold=args.review_high,
        quick_test=args.quick_test,
        plot_umap=args.plot_umap,
        umap_color_by=args.umap_color_by,
    )


if __name__ == "__main__":
    main()
